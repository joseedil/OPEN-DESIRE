

	 --          COMPETITTIVE LEARNING
	 ------------------------------------------------------
	 m=2 |  --                             number of inputs
	 n=20 |  --         number of competitive-layer neurons
	 --
	 ARRAY x[m],v[n],h[n],z[m],W[n,m]
	 --
	 --                          set random initial weights
	 for i=1 to n
	   h[i]=0 |  --                  initialize conscience
	   for k=1 to m
	     W[i,k]=0.0001*ran()
	     next
	   next
	 display N1 |  display C8
	 -----------------------------------------------------
	 --                          set experiment parameters
	 noise=0.1
	 lrate=.02
	 crit=0 |  --                              CLEARN mode
	 scale=1
	 NN=10000
	 -----------------------------------------------------
	 display Q
	 drun  |  --                simulation run (NN trials)
	 write 'type go for a recall run' |  STOP
	 NN=1000 |  a=1/NN |  lrate=0
	 for i=1 to n |  h[i]=1.0E-25 |  next
	 display R
	 drun
	 write 'type go for template entropy (maximize window)' |  STOP
	 ---------------------
	 ONE=0 |  H=0 |  --    initialize checksum and entropy
	 for i=1 to n
	   h[i]=a*h[i] |  --  statistical relative frequencies
	   ONE=ONE+h[i] |  --              accumulate checksum
	   H=H-h[i]*ln(h[i]+1.0E-25) |  --  accumulate entropy
	   next
	 -----------------------------         display results
	 write h |  write
	 write 'H=  ';H/ln(2);' bits','          checksum=  ';ONE
	 write  |  write 'log2 n = ';ln(n)/ln(2)
	 write 'type go to see template matrix' |  STOP
	 write  |  write W
	 ------------------------------------------------------
	 DYNAMIC
	 ------------------------------------------------------
	 --                                 weight-learning run
	 x[1]=ran() |  x[2]=0.8*cos(4*x[1])+noise*ran()
	 CLEARN v=W(x)lrate,crit |  --           compete,learn
	 Vectr delta h=v |  --                            conscience
	 Vector z=W%*v |  --              reconstruct templates
	 DISPXY z[1],z[2]

