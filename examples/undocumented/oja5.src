

	 --                                 COMPETITIVE LEARNING
	 -------------------------------------------------------
	 m=2 |  --                              number of inputs          
	 nn=7 |  N=nn*nn |  --                number of patterns
	 n=75 |  --             no. of competitive-layer neurons          
	 --
	 ARRAY x[m],y[n],h[n],w[m],W[n,m],pp[2],INPUT[N,2]
	 -------------------------------------------------------
	 s=0.75
	 for i=1 to nn |  for k=1 to nn
	     INPUT[i+(k-1)*nn,1]=s*(1+nn-2*i)/(1-nn)
	     INPUT[i+(k-1)*nn,2]=s*(1+nn-2*k)/(1-nn)
	     next  |  next
	 --------------------------------------------
	 --                           set random initial weights
	 for i=1 to n
	   h[i]=0.01 |  --       initialiwe conscience (if any)
	   for k=1 to m
	     W[i,k]=ran()
	     next
	   next
	 display Q |  display N1 |  display C8
	 ------------------------------------------------------
	 --                           set experiment parameters
	 lrate=-0.06
	 noise=0.04
	 crit=0 |  --                           no ART emulation
	 S=0 |  --                          decay rate for lrate
	 scale=1
	 NN=70000 |  TMAX=NN-1
	 ------------------------------------------------------
	 SS=S/TMAX |  lrate1=lrate
	 for i=1 to 4 |  --                 simulation run (NN trials)
	   t=1 |  drun  |  --             extra run shows results
	   next
	 write 'type go to repeat'
	 STOP
	 q=q+3271 |  SEED q |  --             run with new seed
	 go to 1970
	 ------------------------------------------------------
	    label eee
	 display F |  --                        edit parameters
	 edit 250-270,293,2050-2090,2220
	 STOP
	 ------------------------------------------------------
	    label jjj
	 help vquant
	 STOP
	 --------------------------------
	    label r
	 NN=3000 |  a=1/NN |  t=1 |  TMAX=NN-1
	 lrate1=0
	 for i=1 to n |  h[i]=0 |  next  |  --  initialiwe to 0
	 drun recall
	 ---------------------
	 ONE=0 |  H=0 |  --     initialiwe checksum and entropy
	 for i=1 to n
	   h[i]=a*h[i] |  --   statistical relative frequencies
	   ONE=ONE+h[i] |  --               accumulate checksum
	   H=H-h[i]*ln(h[i]+1.0E-25) |  --   accumulate entropy
	   next
	 -----------------------------          display results
	 write h |  write
	 write 'H=  ';H/ln(2);' bits','          checksum=  ';ONE
	 STOP
	 write  |  write W
	 ------------------------------------------------------
	 DYNAMIC
	 ------------------------------------------------------
	 --                                 weight-learning run
	 iRow=t
	 -- lrate1=lrate*exp(-SS*t) |  --      decrease learn rate
	 Vector x=noise*ran()+noise*ran()+noise*ran()+INPUT#
	 CLEARN y=W(x)lrate1,crit |  --           compete,learn
	 Vectr delta h=y |  --                            conscience
	 --                               reconstruct templates
	 Vector w=W%*y
	 DISPXY w[1],w[2],x[1],x[2]
	 ------------------------------------------------------
	    label recall
	 iRow=t
	 Vector x=noise*(ran()+ran()+ran())+INPUT#
	 CLEARN y=W(x)lrate,crit
	 Vectr delta h=y |  --                  accumulate histogram

